import os
import sys
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split


# --- 1. AYARLAR VE YOL BULMA ---
def setup_paths():
    current_dir = os.path.dirname(os.path.abspath(__file__))  # src/modeling
    project_root = os.path.dirname(os.path.dirname(current_dir))  # KararDestek2

    # Preprocessing modÃ¼lÃ¼nÃ¼ bulabilmek iÃ§in sys.path'e ekle
    src_path = os.path.join(project_root, "src")
    if src_path not in sys.path:
        sys.path.append(src_path)

    return project_root


project_root = setup_paths()

# Preprocess fonksiyonunu import et
try:
    from data_preprocessing.preprocess_diabetes import preprocess_diabetes_dataset
except ImportError:
    print("[HATA] 'preprocess_diabetes_dataset' fonksiyonu bulunamadÄ±. LÃ¼tfen sys.path ayarÄ±nÄ± kontrol et.")
    sys.exit(1)


# --- 2. TOPSIS FONKSÄ°YONU ---
def calculate_topsis(df, criteria_cols, weights, benefit_mask):
    """
    df: DeÄŸerlendirilecek veri seti (DataFrame)
    criteria_cols: Kriter sÃ¼tun isimleri listesi
    weights: AÄŸÄ±rlÄ±klar listesi (ToplamÄ± 1 olmalÄ±)
    benefit_mask: [True, True, False...] (True: YÃ¼ksek deÄŸer iyi/riskli, False: DÃ¼ÅŸÃ¼k deÄŸer iyi/riskli)
    """
    # Veriyi seÃ§ ve normalize et (Vector Normalization)
    data = df[criteria_cols].values

    # PaydayÄ± hesapla (KarekÃ¶k toplamÄ±)
    norm = np.sqrt((data ** 2).sum(axis=0))
    normalized_data = data / (norm + 1e-9)  # 0'a bÃ¶lÃ¼nmeyi Ã¶nle

    # AÄŸÄ±rlÄ±klandÄ±r
    weighted_data = normalized_data * weights

    # Ä°deal ve Anti-Ä°deal Ã‡Ã¶zÃ¼mleri Bul
    ideal_solution = []
    anti_ideal_solution = []

    for i, is_benefit in enumerate(benefit_mask):
        if is_benefit:  # YÃ¼ksek deÄŸer riskliyse (Benefit)
            ideal_solution.append(np.max(weighted_data[:, i]))
            anti_ideal_solution.append(np.min(weighted_data[:, i]))
        else:  # DÃ¼ÅŸÃ¼k deÄŸer riskliyse (Cost)
            ideal_solution.append(np.min(weighted_data[:, i]))
            anti_ideal_solution.append(np.max(weighted_data[:, i]))

    ideal_solution = np.array(ideal_solution)
    anti_ideal_solution = np.array(anti_ideal_solution)

    # UzaklÄ±klarÄ± Hesapla (Ã–klid)
    dist_to_ideal = np.sqrt(((weighted_data - ideal_solution) ** 2).sum(axis=1))
    dist_to_anti_ideal = np.sqrt(((weighted_data - anti_ideal_solution) ** 2).sum(axis=1))

    # Skor Hesapla
    topsis_score = dist_to_anti_ideal / (dist_to_ideal + dist_to_anti_ideal + 1e-9)
    return topsis_score


# --- 3. GRAFÄ°K OLUÅTURMA FONKSÄ°YONU ---
def generate_plots(df, output_dir):
    """
    Rapor iÃ§in gerekli grafikleri oluÅŸturur ve kaydeder.
    """
    print("[INFO] Grafikler oluÅŸturuluyor...")
    sns.set_style("whitegrid")

    # KlasÃ¶r yoksa oluÅŸtur
    plot_dir = os.path.join(output_dir, "plots")
    os.makedirs(plot_dir, exist_ok=True)

    # Veriyi GÃ¶rselleÅŸtirme Ä°Ã§in HazÄ±rla
    df['Readmitted_Binary'] = df['actual_readmission_text'].apply(lambda x: 'HayÄ±r' if x == 'NO' else 'Evet')

    # --- GRAFÄ°K 1: XGBoost Risk vs TOPSIS Skor (Scatter Plot) ---
    plt.figure(figsize=(10, 6))
    sns.scatterplot(
        data=df,
        x='xgboost_risk_score',
        y='topsis_score',
        hue='Readmitted_Binary',
        palette={'Evet': '#d62728', 'HayÄ±r': '#1f77b4'},  # KÄ±rmÄ±zÄ± ve Mavi
        alpha=0.7,
        s=60
    )
    plt.title("Yapay Zeka Riski vs. Karar Destek PuanÄ± (AHP Destekli)", fontsize=14)
    plt.xlabel("XGBoost Risk OlasÄ±lÄ±ÄŸÄ±", fontsize=12)
    plt.ylabel("AHP-TOPSIS Ã–ncelik Skoru", fontsize=12)
    plt.plot([0, 1], [0, 1], 'k--', alpha=0.3)
    plt.tight_layout()
    plt.savefig(os.path.join(plot_dir, "1_scatter_risk_vs_topsis_ahp.png"), dpi=300)
    plt.close()

    # --- GRAFÄ°K 2: Top N BaÅŸarÄ± Analizi (Bar Chart) ---
    top_n = 100

    # Sadece Model ile sÄ±ralama
    top_xgb = df.sort_values(by='xgboost_risk_score', ascending=False).head(top_n)
    hits_xgb = top_xgb[top_xgb['Readmitted_Binary'] == 'Evet'].shape[0]

    # TOPSIS ile sÄ±ralama
    top_topsis = df.sort_values(by='topsis_score', ascending=False).head(top_n)
    hits_topsis = top_topsis[top_topsis['Readmitted_Binary'] == 'Evet'].shape[0]

    plt.figure(figsize=(9, 6))
    bars = plt.bar(['Sadece Yapay Zeka (XGBoost)', 'Hibrit Sistem (AHP+TOPSIS)'], [hits_xgb, hits_topsis],
                   color=['gray', '#2ca02c'])
    plt.title(f"En Riskli {top_n} Hastada Yakalanan GerÃ§ek Vaka SayÄ±sÄ±", fontsize=14)
    plt.ylabel("DoÄŸru Tespit SayÄ±sÄ±", fontsize=12)
    plt.grid(axis='y', linestyle='--', alpha=0.7)

    for bar in bars:
        yval = bar.get_height()
        plt.text(bar.get_x() + bar.get_width() / 2, yval + 1, int(yval), ha='center', va='bottom', fontweight='bold',
                 fontsize=12)

    plt.tight_layout()
    plt.savefig(os.path.join(plot_dir, "2_success_comparison_ahp.png"), dpi=300)
    plt.close()

    # --- GRAFÄ°K 3: TOPSIS Skorunun Duruma GÃ¶re DaÄŸÄ±lÄ±mÄ± (Box Plot) ---
    plt.figure(figsize=(8, 6))
    sns.boxplot(data=df, x='Readmitted_Binary', y='topsis_score', palette={'Evet': '#d62728', 'HayÄ±r': '#1f77b4'})
    plt.title("GerÃ§ek Duruma GÃ¶re TOPSIS Skor DaÄŸÄ±lÄ±mÄ±", fontsize=14)
    plt.xlabel("GerÃ§ekte Tekrar YattÄ± mÄ±?", fontsize=12)
    plt.ylabel("AHP-TOPSIS Skoru", fontsize=12)
    plt.tight_layout()
    plt.savefig(os.path.join(plot_dir, "3_boxplot_topsis_distribution_ahp.png"), dpi=300)
    plt.close()

    print(f"[INFO] Grafikler kaydedildi: {plot_dir}")


def main():
    print("--- KLÄ°NÄ°K KARAR DESTEK SÄ°STEMÄ° (XGBoost + AHP + TOPSIS) ---")

    # A. Dosya YollarÄ±
    model_path = os.path.join(project_root, "src", "modeling", "models", "models", "xgb_weighted_f2", "model.joblib")
    csv_path = os.path.join(project_root, "data", "raw", "diabetic_data.csv")

    if not os.path.exists(model_path):
        model_path = os.path.join(project_root, "src", "modeling", "models", "xgb_weighted_f2", "model.joblib")

    print(f"[INFO] Model Yolu: {model_path}")

    # B. Modeli YÃ¼kle
    if not os.path.exists(model_path):
        print(f"[HATA] Model dosyasÄ± bulunamadÄ±! Path: {model_path}")
        return

    saved_data = joblib.load(model_path)
    model = saved_data["model"]
    feature_names = saved_data["feature_names"]

    print("[INFO] Model baÅŸarÄ±yla yÃ¼klendi.")

    # C. Veriyi HazÄ±rla
    print("[INFO] Model girdileri hazÄ±rlanÄ±yor (Preprocess)...")
    _, _, _, _, X_test_proc, y_test, _ = preprocess_diabetes_dataset(csv_path)
    print(f"[INFO] Ä°ÅŸlenmiÅŸ Test Seti Boyutu: {X_test_proc.shape[0]} satÄ±r")

    # 2. Orijinal Veri EÅŸleÅŸtirme
    print("[INFO] Orijinal hasta verileri eÅŸleÅŸtiriliyor...")
    df_raw = pd.read_csv(csv_path)
    df_raw = df_raw.replace('?', np.nan)
    df_raw = df_raw[~df_raw['discharge_disposition_id'].isin([11, 13, 14, 19, 20, 21])]
    df_raw = df_raw.sort_values('encounter_id')
    df_raw = df_raw.drop_duplicates(subset=['patient_nbr'], keep='first')

    df_train, df_temp = train_test_split(df_raw, test_size=0.3, random_state=42, stratify=df_raw['readmitted'])
    df_valid, df_test_original = train_test_split(df_temp, test_size=0.5, random_state=42,
                                                  stratify=df_temp['readmitted'])

    print(f"[INFO] EÅŸleÅŸtirilen Orijinal Veri Boyutu: {df_test_original.shape[0]} satÄ±r")

    if X_test_proc.shape[0] != df_test_original.shape[0]:
        print("\n[KRÄ°TÄ°K HATA] SatÄ±r sayÄ±larÄ± uyuÅŸmuyor!")
        return

    # Tahmin Al
    print("[INFO] Risk skorlarÄ± hesaplanÄ±yor...")
    if hasattr(X_test_proc, "columns"):
        for col in feature_names:
            if col not in X_test_proc.columns:
                X_test_proc[col] = 0
        X_test_aligned = X_test_proc[feature_names]
        y_pred_prob = model.predict_proba(X_test_aligned)[:, 1]
    else:
        y_pred_prob = model.predict_proba(X_test_proc)[:, 1]

    # D. TOPSIS Veri Seti
    # D. TOPSIS Veri Seti
    # C1â€“C5 iÃ§in gerekli kolonlarÄ± raw test veri setinden al
    cols_needed = [
        'encounter_id',
        'patient_nbr',
        'time_in_hospital',
        'number_emergency',
        'number_inpatient',
        'number_outpatient',
        'num_procedures',
        'number_diagnoses',
        'A1Cresult',
        # EÄŸer daha Ã¶nce preprocess'te oluÅŸturduÄŸun diag_1_group_ord kolonlarÄ± raw'a eklenmiÅŸse:
        # 'diag_1_group_ord', 'diag_2_group_ord', 'diag_3_group_ord'
        # yoksa aÅŸaÄŸÄ±da basit bir proxy kullanacaÄŸÄ±z.
    ]
    # Sadece var olan kolonlarÄ± al (eksik varsa hata vermesin diye filtreliyoruz)
    cols_existing = [c for c in cols_needed if c in df_test_original.columns]
    df_topsis = df_test_original[cols_existing].copy()

    # C1: XGBoost risk skoru
    df_topsis['xgboost_risk_score'] = y_pred_prob

    # GerÃ§ek readmission label'Ä±nÄ± da saklayalÄ±m
    df_topsis['actual_readmission_text'] = df_test_original['readmitted']

    # C2: Total visits = inpatient + emergency + outpatient
    for col in ['number_inpatient', 'number_emergency', 'number_outpatient']:
        if col not in df_topsis.columns:
            raise ValueError(f"TOPSIS iÃ§in {col} sÃ¼tunu eksik, lÃ¼tfen df_test_original iÃ§inde olduÄŸundan emin olun.")

    df_topsis['total_visits'] = (
            df_topsis['number_inpatient'] +
            df_topsis['number_emergency'] +
            df_topsis['number_outpatient']
    )

    # C4: A1Cresult_ord (0: None, 1: Norm, 2: >7, 3: >8)
    if 'A1Cresult' in df_topsis.columns:
        a1c_map = {
            'None': 0,
            'Norm': 1,
            '>7': 2,
            '>8': 3
        }
        df_topsis['A1Cresult_ord'] = df_topsis['A1Cresult'].map(a1c_map).fillna(0).astype(int)
    else:
        raise ValueError("TOPSIS iÃ§in 'A1Cresult' sÃ¼tunu bulunamadÄ±.")

    # C5: TanÄ± aÄŸÄ±rlÄ±ÄŸÄ± (diag_1_group_ord + diag_2_group_ord + diag_3_group_ord)
    # EÄŸer raw iÃ§inde diag_*_group_ord yoksa, basit proxy olarak number_diagnoses kullanabiliriz.
    if all(col in df_topsis.columns for col in ['diag_1_group_ord', 'diag_2_group_ord', 'diag_3_group_ord']):
        df_topsis['diag_severity'] = (
                df_topsis['diag_1_group_ord'] +
                df_topsis['diag_2_group_ord'] +
                df_topsis['diag_3_group_ord']
        )
    else:
        # Proxy Ã§Ã¶zÃ¼m: tanÄ± sayÄ±sÄ±nÄ± komorbidite gÃ¶stergesi olarak kullan
        if 'number_diagnoses' not in df_topsis.columns:
            raise ValueError(
                "TanÄ± aÄŸÄ±rlÄ±ÄŸÄ± iÃ§in ne diag_*_group_ord ne de number_diagnoses bulundu. "
                "LÃ¼tfen preprocess ile bu alanlarÄ± ekleyin."
            )
        df_topsis['diag_severity'] = df_topsis['number_diagnoses']

    print("[INFO] TOPSIS hesaplanÄ±yor (AHP AÄŸÄ±rlÄ±klarÄ± ile)...")

    # --- AHP ENTEGRASYONU ---
    # C1: xgboost_risk_score
    # C2: total_visits
    # C3: time_in_hospital
    # C4: A1Cresult_ord
    # C5: diag_severity

    criteria = [
        'xgboost_risk_score',
        'total_visits',
        'time_in_hospital',
        'A1Cresult_ord',
        'diag_severity'
    ]

    # AHP'den gelen aÄŸÄ±rlÄ±klar (Ã¶rnek: w1=0.49, w2=0.23, w3=0.06, w4=0.09, w5=0.13)
    # Burada daha Ã¶nce konuÅŸtuÄŸumuz:
    # C1: 0.49 (ML risk)
    # C2: 0.23 (total visits)
    # C3: 0.06 (time in hospital)
    # C4: 0.09 (A1C)
    # C5: 0.13 (diag severity)
    weights = np.array([0.49, 0.23, 0.06, 0.09, 0.13], dtype=float)
    weights = weights / weights.sum()  # normalize, gÃ¼venlik iÃ§in

    # Bu kriterlerin hepsi "daha bÃ¼yÃ¼k = daha riskli" olduÄŸu iÃ§in benefit=True
    benefit = [True, True, True, True, True]

    scores = calculate_topsis(df_topsis, criteria, weights, benefit)
    df_topsis['topsis_score'] = scores
    # E. SÄ±ralama ve Rapor
    df_sorted = df_topsis.sort_values(by='topsis_score', ascending=False)

    print("\n" + "=" * 90)
    print("ğŸš¨ AHP-TOPSIS SONUCU: ACÄ°L MÃœDAHALE GEREKTÄ°REN EN RÄ°SKLÄ° 15 HASTA ğŸš¨")
    print("=" * 90)

    top_15 = df_sorted.head(15)

    print(
        f"{'Patient ID':<12} | {'Risk(%)':<8} | {'Acil':<5} | {'GÃ¼n':<4} | {'Ä°ÅŸlem':<5} | {'AHP-TOPSIS':<10} | {'Durum'}")
    print("-" * 100)
    for index, row in top_15.iterrows():
        print(
            f"{row['patient_nbr']:<12} | {row['xgboost_risk_score']:.4f}   | {row['number_emergency']:<5} | {row['time_in_hospital']:<4} | {row['num_procedures']:<5} | {row['topsis_score']:.4f}       | {row['actual_readmission_text']}")

    # F. Kaydet
    report_dir = os.path.join(project_root, "reports")
    output_path = os.path.join(report_dir, "patient_risk_ranking_ahp.xlsx")
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    df_sorted.to_excel(output_path, index=False)
    print(f"\n[INFO] Rapor kaydedildi: {output_path}")

    # G. Grafikleri OluÅŸtur
    generate_plots(df_sorted, report_dir)


if __name__ == "__main__":
    main()